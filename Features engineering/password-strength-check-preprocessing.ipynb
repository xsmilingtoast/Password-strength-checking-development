{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3176,"sourceType":"datasetVersion","datasetId":1835},{"sourceId":3976,"sourceType":"datasetVersion","datasetId":2367},{"sourceId":523227,"sourceType":"datasetVersion","datasetId":248604},{"sourceId":2820319,"sourceType":"datasetVersion","datasetId":1724587},{"sourceId":10700429,"sourceType":"datasetVersion","datasetId":6631090}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pyahocorasick\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ahocorasick","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/password-strength-classifier-dataset/data.csv' , on_bad_lines = 'skip')\nvocabset = pd.read_csv('/kaggle/input/english-word-frequency-list/ngram_freq.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab_df = vocabset.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Test train split ","metadata":{}},{"cell_type":"code","source":"def extract_features(password: str):\n    features = {\n        'length': len(password),\n        'uppercase': sum(1 for char in password if char.isupper()),\n        'lowercase': sum(1 for char in password if char.islower()),\n        'digits': sum(1 for char in password if char.isdigit()),\n        'special_chars': sum(1 for char in password if not char.isalnum())\n    }\n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['password'] = data['password'].astype(str)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df = pd.DataFrame([{'password' : data['password'].iloc[i] , 'strength' : data['strength'].iloc[i] ,\n                       **extract_features(data['password'].iloc[i])} for i in range(len(data))])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = new_df.drop(columns=['strength'])  # Features\ny = new_df['strength']                  # Target/Labels\n\n# Split the dataset into training and testing sets with a 3:7 ratio\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y, \n    test_size=0.7,   # 70% test size, thus 30% train size\n    stratify=y,      # Ensures class distribution is maintained\n    random_state=42  # For reproducibility\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"actual_words = vocab_df[vocab_df['word'].str.len() > 1 ] ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q_25 , q_50 , q_75 , q_90 = actual_words['count'].quantile([0.25,0.5,0.75 ,0.90])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q_25","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def classify_words_by_quantiles(df):\n    actual_words = df.copy()\n    # Calculate quantile thresholds\n    q_25, q_50, q_75, q_90 = actual_words['count'].quantile([0.25, 0.5, 0.75, 0.90])\n\n    # Classify based on quantiles using pd.cut\n    bins = [-float('inf'), q_25, q_50, q_75, q_90, float('inf')]\n    labels = ['very_low', 'low', 'medium', 'high', 'very_high']\n\n    actual_words['Occurance'] = pd.cut(actual_words['count'], bins=bins, labels=labels)\n\n    # Create the new DataFrame directly\n    new_vocab = actual_words[['word', 'count', 'Occurance']].copy()\n\n    return new_vocab","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"actual_words = pd.DataFrame(actual_words)\n\nnew_vocab_df = classify_words_by_quantiles(actual_words)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_vocab_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab_list = [new_vocab_df['word'].iloc[i] for i in range(len(new_vocab_df['word']))] ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"password_list = new_df['password'].tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_vocab_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert to dictionary for fast lookup\nvocab_tiers = dict(zip(new_vocab_df['word'], new_vocab_df['Occurance']))\n\n# Define tier priority\ntier_priority = {'very_low': 1, 'low': 2, 'medium': 3 , 'high':4 , 'very_high':5}  # Higher number = higher priority\n\n# Initialize the automaton\nautomaton = ahocorasick.Automaton()\n\n# Add words to automaton with tier info\nfor word, tier in vocab_tiers.items():\n    automaton.add_word(word.lower(), (word.lower(), tier))\n\n# Finalize automaton for fast searching\nautomaton.make_automaton()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def check_password_debug(password):\n    # Normalize the password to lowercase.\n    text = str(password).lower()\n    matched_words = set()  # Using a set to keep unique matched words.\n    highest_tier = \"none\"    # Default tier if no words are found.\n    highest_priority = 0\n\n    # Iterate over all matches in the password using the automaton.\n    for end_index, (word, tier) in automaton.iter(text):\n        matched_words.add(word)  # Add the word to our set.\n        current_priority = tier_priority.get(tier, 0)\n        # Update the highest tier if this word's tier has a higher priority.\n        if current_priority > highest_priority:\n            highest_priority = current_priority\n            highest_tier = tier\n\n    # Return a sorted list (optional, for easier debugging) and the highest tier.\n    return sorted(matched_words), highest_tier\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df[['contain_vocab', 'vocab_tier']] = new_df['password'].apply(    lambda x: pd.Series(check_password_debug(x)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df = new_df.drop(columns = 'contain_vocab')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_entropy(password):\n    # A rough estimation using Shannon entropy.\n    if not password:\n        return 0\n    freq = {}\n    for char in password:\n        freq[char] = freq.get(char, 0) + 1\n    entropy = 0.0\n    for count in freq.values():\n        p = count / len(password)\n        entropy -= p * math.log2(p)\n    return entropy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ratio features extraction","metadata":{}},{"cell_type":"code","source":"def normalize(password):\n    substitutions = {\n        'a': ['@', '4'],\n        'b': ['8'],\n        'c': ['(', '<', '{', '['],\n        'd': ['|)'],\n        'e': ['3'],\n        'f': [],         # No common replacement, but can add one if needed\n        'g': ['6', '9'],\n        'h': ['#'],\n        'i': ['1', '!'],  # 'i' -> '1' (or '!')\n        'j': [],\n        'k': [],\n        'l': ['1', '|'],\n        'm': [],         # Could add common alternatives if desired\n        'n': [],\n        'o': ['0'],\n        'p': [],\n        'q': [],\n        'r': [],\n        's': ['5', '$'],\n        't': ['7'],\n        'u': ['v'],      # sometimes 'u' is replaced with 'v'\n        'v': [],\n        'w': ['vv'],\n        'x': ['%'],\n        'y': [],\n        'z': ['2']\n    }\n    \n    normalized_chars = []\n    for ch in password.lower():\n        rep = substitutions.get(ch, ch)\n        if isinstance(rep, list):\n            # If the list is non-empty, use the first replacement; otherwise, use the original character.\n            normalized_chars.append(rep[0] if rep else ch)\n        else:\n            normalized_chars.append(rep)\n    return ''.join(normalized_chars)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ratio_feature_extract(password:str) : \n    features = {}\n    # Ensure password is a string\n    password = str(password)\n    \n    # Check if the password is not empty\n    if len(password) > 0:\n        features['num_upper'] = sum(1 for c in password if c.isupper())\n        features['num_lower'] = sum(1 for c in password if c.islower())\n        features['num_digits'] = sum(1 for c in password if c.isdigit())\n        features['num_special'] = len(password) - features['num_upper'] - features['num_lower'] - features['num_digits']\n        \n        features['upper_ratio'] = features['num_upper'] / len(password)\n        features['lower_ratio'] = features['num_lower'] / len(password)\n        features['digit_ratio'] = features['num_digits'] / len(password)\n        features['special_ratio'] = features['num_special'] / len(password)\n    else:\n        # If password is empty, define all features as 0\n        features['num_upper'] = features['num_lower'] = features['num_digits'] = features['num_special'] = 0\n        features['upper_ratio'] = features['lower_ratio'] = features['digit_ratio'] = features['special_ratio'] = 0\n\n    features['entropy'] = calculate_entropy(password)\n\n    return features\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_series = data['password'].apply(ratio_feature_extract)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_series","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_df = pd.DataFrame(features_series.tolist())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df_all = pd.concat([new_df, features_df], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df_all.to_csv('/kaggle/working/pretrain_dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T05:19:22.192585Z","iopub.execute_input":"2025-02-12T05:19:22.192896Z","iopub.status.idle":"2025-02-12T05:19:26.344282Z","shell.execute_reply.started":"2025-02-12T05:19:22.192869Z","shell.execute_reply":"2025-02-12T05:19:26.343360Z"}},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"Actual model making ","metadata":{}},{"cell_type":"code","source":"preprocessed_df = pd.read_csv('/kaggle/working/preprocessed_data.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocessed_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}